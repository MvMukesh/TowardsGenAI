# TowardsGenAI

### Text Preprocessing & Word Embedding
|Topic                    |Link    |
|-------------------------|--------|
|Why Text Preprocessing?  |        |
|Text Cleaning | |
|Stop Words Removal | |
|Lemmatization & Stemming | |
|Normalization & Text Segmentation| |
|POS & NER | |
|One Hot Encoding | |
|BOW | |
|TF-IDF | |
|Word2Vec | |
|Intro to Word Embedding | |
|Word Embedding & Text Preprocessing| |


### Into Neural Networks
|Topic                    |Link    |
|-------------------------|--------|
|Perceptron               |        |
|Perceptron Working + Components    |        |
|Multilayer Perceptron              |        |
|Forward & Backward Propagation     |        |
|Chain Rule + Weights               |        |
|Vanishing gradient Problem         |        |
|Exploding gradient Problem         |        |


### Into Activation Function
|Topic                              |Link    |
|-----------------------------------|--------|
|Sigmoid & TanH      |        |
|Relue & it's types  |        |
|Softmax & Swish     |        |


### Into Loss Function
|Topic                              |Link    |
|-----------------------------------|--------|
|MAE, MSE & Huber Loss      |        |
|Binary & Categorical Loss  |        |
|Softmax & Swish     |        |


### Into Optimizers
|Topic                              |Link    |
|-----------------------------------|--------|
|GD - Batch, Stochastic, Mini Batch |        |
|SGD with Momentum & Adagrad        |        |
|RMS prop & Adam Optimizers         |        |


### Into Algorithms
|Topic                              |Link    |
|-----------------------------------|--------|
|RNN, Bptt|    |
|Types of RNN| |
|Problem in RNN & Solution| |
|- |- |
|LSTMs | |
|GRU | |
|BiDirectional RNN | |
|Transformers | |


